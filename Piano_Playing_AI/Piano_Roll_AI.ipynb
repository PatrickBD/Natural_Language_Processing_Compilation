{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colab Block\n",
    "I usually run my notebooks in Colabratory, which has a free 12GB GPU to connect to and use. Files are most easily accessed via a Google Drive, but that needs to be connected to and authenticated twice via this block. Also, some packages need to be installed again every runtime. So that is what this first block does, remove if not using Colab's notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 2893,
     "output_extras": [
      {
       "item_id": 14
      },
      {
       "item_id": 49
      },
      {
       "item_id": 68
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 93229,
     "status": "ok",
     "timestamp": 1522558712749,
     "user": {
      "displayName": "Valkling FriendofAllThings",
      "photoUrl": "//lh5.googleusercontent.com/-fEy3QF-eaHI/AAAAAAAAAAI/AAAAAAAAAnM/he6PEcG-E94/s50-c-k-no/photo.jpg",
      "userId": "113638037001591500423"
     },
     "user_tz": 240
    },
    "id": "6d_2V8DvRAmh",
    "outputId": "08911133-b42d-4c30-a38e-d0bd55a5f8ff"
   },
   "outputs": [],
   "source": [
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
    "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
    "!apt-get update -qq 2>&1 > /dev/null\n",
    "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
    "from oauth2client.client import GoogleCredentials\n",
    "creds = GoogleCredentials.get_application_default()\n",
    "import getpass\n",
    "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
    "vcode = getpass.getpass()\n",
    "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
    "!mkdir -p gdrive\n",
    "!google-drive-ocamlfuse gdrive\n",
    "!pip install -q keras\n",
    "!pip install numba\n",
    "!pip install tqdm\n",
    "!pip install opencv-python\n",
    "!apt update && apt install -y libsm6 libxext6\n",
    "!pip install music21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8343,
     "status": "ok",
     "timestamp": 1522558754218,
     "user": {
      "displayName": "Valkling FriendofAllThings",
      "photoUrl": "//lh5.googleusercontent.com/-fEy3QF-eaHI/AAAAAAAAAAI/AAAAAAAAAnM/he6PEcG-E94/s50-c-k-no/photo.jpg",
      "userId": "113638037001591500423"
     },
     "user_tz": 240
    },
    "id": "lGfTAI5XRAmv",
    "outputId": "4dcc8c4c-2399-4778-8fa7-1d3b2fa8f10e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "import keras as K\n",
    "\n",
    "from music21 import converter, instrument, note, chord, stream\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, MaxPooling1D, Conv1D\n",
    "from keras.layers import Dropout, Bidirectional, SpatialDropout1D\n",
    "from keras.layers import LSTM, GRU, Flatten,CuDNNLSTM, CuDNNGRU\n",
    "from keras.layers import Activation\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "# import mido\n",
    "# from mido import MidiFile\n",
    "\n",
    "# mid = MidiFile('C:/Users/Valkling/Dropbox/my_personal_programs/Music_Bot/midicsv-1.1.tar/midicsv-1.1/test.mid')\n",
    "\n",
    "# DirPath = \"C:\\Users\\Valkling\\Dropbox\\my_personal_programs\\Music_Bot\\midicsv-1.1.tar\\midicsv-1.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZcXvIst1RAmz"
   },
   "source": [
    "# Read in Midi Files\n",
    "Place any midi files you would like to read in an attached midi_songs folder and uncomment this block. Alternatively, just load the pre-packed .npy file in the next block for a pre-read in dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51,
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 952,
     "status": "ok",
     "timestamp": 1522117792052,
     "user": {
      "displayName": "Patrick DeKelly",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113168316542890578910"
     },
     "user_tz": 240
    },
    "id": "w23TKrAKRAm0",
    "outputId": "4e26ae59-5b18-40d8-c2c6-44f97a4565ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1e+03 µs, sys: 0 ns, total: 1e+03 µs\n",
      "Wall time: 639 ms\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# notes = []\n",
    "\n",
    "# for file in glob.glob(\"../midi_songs/*.mid\"):\n",
    "#     try:\n",
    "#         midi = converter.parse(file)\n",
    "\n",
    "#         notes_to_parse = None\n",
    "\n",
    "#         parts = instrument.partitionByInstrument(midi)\n",
    "# #         print(file)\n",
    "#         if parts: # file has instrument parts\n",
    "#             notes_to_parse = parts.parts[0].recurse()\n",
    "#         else: # file has notes in a flat structure\n",
    "#             notes_to_parse = midi.flat.notes\n",
    "#     #     print(\"here\")\n",
    "#         for element in notes_to_parse:\n",
    "#             if isinstance(element, note.Note):\n",
    "#                 notes.append(str(element.pitch))\n",
    "#             elif isinstance(element, chord.Chord):\n",
    "#                 notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "# #         print(\"here\")\n",
    "#     except:\n",
    "#         print(\"file failed\")\n",
    "# # with open('../data/notes', 'wb') as filepath:\n",
    "# #     pickle.dump(notes, filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "_ahCYor2SzRD"
   },
   "outputs": [],
   "source": [
    "notes = np.load(\"gdrive/Music_Bot/midiset.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wf9v803LRAm6"
   },
   "source": [
    "# Notes to sequences\n",
    "cuts notes into a series of 100 note arrays with the next (as in 101st) note placed in a different array to use as the Y variable in the model. Basically, we are using the last 100 notes to predict the next note."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "w3QH97cTRAm7"
   },
   "outputs": [],
   "source": [
    "notesbackup = notes\n",
    "n_vocab = len(set(notes))\n",
    "\n",
    "sequence_length = 100\n",
    "\n",
    "pitchnames = sorted(set(item for item in notes))\n",
    "\n",
    "note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "\n",
    "network_input = []\n",
    "network_output = []\n",
    "\n",
    "for i in range(0, len(notes) - sequence_length, 1):\n",
    "    sequence_in = notes[i:i + sequence_length]\n",
    "    sequence_out = notes[i + sequence_length]\n",
    "    network_input.append([note_to_int[char] for char in sequence_in])\n",
    "    network_output.append(note_to_int[sequence_out])\n",
    "\n",
    "n_patterns = len(network_input)\n",
    "\n",
    "network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "\n",
    "network_input = network_input / float(n_vocab)\n",
    "\n",
    "network_output = np_utils.to_categorical(network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 444,
     "status": "ok",
     "timestamp": 1522558763882,
     "user": {
      "displayName": "Valkling FriendofAllThings",
      "photoUrl": "//lh5.googleusercontent.com/-fEy3QF-eaHI/AAAAAAAAAAI/AAAAAAAAAnM/he6PEcG-E94/s50-c-k-no/photo.jpg",
      "userId": "113638037001591500423"
     },
     "user_tz": 240
    },
    "id": "nVJM6gYzRAnA",
    "outputId": "6774cae8-0a42-4601-86d9-e49f0b2d0622"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57077, 100, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_input.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KJjjfTGeRAnE"
   },
   "source": [
    "# Set up Model\n",
    "The model is 3 LSTMs stacked on top of each other. 3 LSTMs causes the model to hang at over 4.0 loss for the first 40 minutes or so of training time before taking off. Note that the CuDNNLSTMs are a special Nvida layer that automatically optimizes the LSTMs to work around twice as fast but needs to be used with certain GPUs. Colab's GPU is compatable and all set for it but replace with regular LSTMs if the layers won't work for you. (Still only try this code with a good GPU, this code would take to long on CPU or even an underpowerd GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 408,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2528,
     "status": "ok",
     "timestamp": 1522524083276,
     "user": {
      "displayName": "Valkling FriendofAllThings",
      "photoUrl": "//lh5.googleusercontent.com/-fEy3QF-eaHI/AAAAAAAAAAI/AAAAAAAAAnM/he6PEcG-E94/s50-c-k-no/photo.jpg",
      "userId": "113638037001591500423"
     },
     "user_tz": 240
    },
    "id": "keXczPsSRAnG",
    "outputId": "acbe14e5-183d-41ef-d639-c1a11c346a9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cu_dnnlstm_4 (CuDNNLSTM)     (None, 100, 512)          1054720   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100, 512)          0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_5 (CuDNNLSTM)     (None, 100, 512)          2101248   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100, 512)          0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_6 (CuDNNLSTM)     (None, 512)               2101248   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 358)               92006     \n",
      "=================================================================\n",
      "Total params: 5,480,550\n",
      "Trainable params: 5,480,550\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(CuDNNLSTM(512, return_sequences=True, \n",
    "               input_shape=(network_input.shape[1], network_input.shape[2])))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(CuDNNLSTM(512, return_sequences=True))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(CuDNNLSTM(512,))\n",
    "model.add(Dense(256, activation='elu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(n_vocab, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kWeWD5YCRAnJ"
   },
   "source": [
    "# Checkpoint Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "iad6UpVyRAnL"
   },
   "outputs": [],
   "source": [
    "filepath = \"../best_weights.hdf5\"\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath,\n",
    "    monitor='loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "okYAnovd2xiU"
   },
   "outputs": [],
   "source": [
    "# model = K.models.load_model(\"gdrive/Music_Bot/best_weights.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fa1JazavRAnU"
   },
   "source": [
    "# Train the Model\n",
    "Run until you are satisfied with the loss. Under 1.0 loss at least for something knid of like music. 0.5 is pretty good, around 0.2 is about as good as it will get. Can be run longer than that but will take a long time and getting the loss too low might result in too much overfitting and then the midi files are just being repeated in the most inefficent way possible. Basically, the program is going to try to predict the music perfectly and we want it to make *just* enough errors in its prediction to create new music but not so much that it still sounds like music."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 3702,
     "output_extras": [
      {
       "item_id": 66
      },
      {
       "item_id": 79
      },
      {
       "item_id": 80
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6518188,
     "status": "error",
     "timestamp": 1522565357818,
     "user": {
      "displayName": "Valkling FriendofAllThings",
      "photoUrl": "//lh5.googleusercontent.com/-fEy3QF-eaHI/AAAAAAAAAAI/AAAAAAAAAnM/he6PEcG-E94/s50-c-k-no/photo.jpg",
      "userId": "113638037001591500423"
     },
     "user_tz": 240
    },
    "id": "D76EVg3sRAnV",
    "outputId": "91245c5b-e137-4385-fac6-8e9ac9694573"
   },
   "outputs": [],
   "source": [
    "tf.initialize_all_variables\n",
    "model.fit(network_input, \n",
    "          network_output, \n",
    "          epochs=1000, \n",
    "          batch_size=64, \n",
    "          callbacks=callbacks_list,\n",
    "          verbose=2,\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "TaT_NP31RAnd"
   },
   "outputs": [],
   "source": [
    "# model.load_weights(filepath)\n",
    "# model.save_weights(\"../Best_Overall_Weights.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "0PReNWgBzzR-"
   },
   "outputs": [],
   "source": [
    "# model.save(../Best_Overall_model.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3nVjtMUxRAnb"
   },
   "source": [
    "# Generate Music\n",
    "We create the music by giving the model a random sample from our data set to predict on. Then we append the newly predicted note to the end of our pattern,drop the first note, then use that pattern to predict the next and so on. set to 1000 notes right now, or around a 4 minute midi file. The first 20 seconds of an output tend to sound iffy while the computer finds it's rhythm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "PfbFFeccRAng"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "start = np.random.randint(0, len(network_input)-1)\n",
    "int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
    "pattern = network_input[start]\n",
    "prediction_output = []\n",
    "for note_index in range(1000):\n",
    "    prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    prediction_input = prediction_input / float(n_vocab)\n",
    "    prediction = model.predict(prediction_input, verbose=0)\n",
    "    index = np.argmax(prediction)\n",
    "    result = int_to_note[index]\n",
    "    prediction_output.append(result)\n",
    "    pattern = np.append(pattern,index)\n",
    "    pattern = pattern[1:len(pattern)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block translates our notes prediction into a midi format. raising or lowering the offset += at the bottom will change the notes playback speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 610,
     "status": "ok",
     "timestamp": 1522558802993,
     "user": {
      "displayName": "Valkling FriendofAllThings",
      "photoUrl": "//lh5.googleusercontent.com/-fEy3QF-eaHI/AAAAAAAAAAI/AAAAAAAAAnM/he6PEcG-E94/s50-c-k-no/photo.jpg",
      "userId": "113638037001591500423"
     },
     "user_tz": 240
    },
    "id": "HET8fNcXRAnk",
    "outputId": "6f1880d0-1d78-469b-ad5f-f44181e7fb64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 256 ms, sys: 6 ms, total: 262 ms\n",
      "Wall time: 256 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "offset = 0\n",
    "output_notes = []\n",
    "for pattern in prediction_output:\n",
    "    if ('.' in pattern) or pattern.isdigit():\n",
    "        notes_in_chord = pattern.split('.')\n",
    "        notes = []\n",
    "        for current_note in notes_in_chord:\n",
    "            new_note = note.Note(int(current_note))\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            notes.append(new_note)\n",
    "        new_chord = chord.Chord(notes)\n",
    "        new_chord.offset = offset\n",
    "        output_notes.append(new_chord)\n",
    "    else:\n",
    "        new_note = note.Note(pattern)\n",
    "        new_note.offset = offset\n",
    "        new_note.storedInstrument = instrument.Piano()\n",
    "        output_notes.append(new_note)\n",
    "    offset += 0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TR7oJ1MxRAnr"
   },
   "source": [
    "# Output the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3325,
     "status": "ok",
     "timestamp": 1522558818224,
     "user": {
      "displayName": "Valkling FriendofAllThings",
      "photoUrl": "//lh5.googleusercontent.com/-fEy3QF-eaHI/AAAAAAAAAAI/AAAAAAAAAnM/he6PEcG-E94/s50-c-k-no/photo.jpg",
      "userId": "113638037001591500423"
     },
     "user_tz": 240
    },
    "id": "6vBozXBcRAns",
    "outputId": "43b3507f-7ac4-4b25-844b-35b20c2834e6"
   },
   "outputs": [],
   "source": [
    "midi_stream = stream.Stream(output_notes)\n",
    "midi_stream.write('midi', fp='../test_output.mid')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "Midi_Reader.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
