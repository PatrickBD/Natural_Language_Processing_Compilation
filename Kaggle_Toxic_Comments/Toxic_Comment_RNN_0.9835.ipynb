{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Toxic Comment RNN.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"_XHkXQS_E_gy","colab_type":"text"},"cell_type":"markdown","source":["# Import\n","This first block is only for starting in Colabratory. Some pips need to be re-installed each time and authentication codes need to be entered from links to allow access to google drive files. The free GPU service is well worth the small inconvenience. Remove this block if not using Colabratory."]},{"metadata":{"id":"qNJeXxSQFMgO","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from google.colab import auth\n","auth.authenticate_user()\n","!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n","!mkdir -p drive\n","!google-drive-ocamlfuse drive\n","!pip install -q keras\n","!pip install numba"],"execution_count":0,"outputs":[]},{"metadata":{"id":"VPuj4pk31eDh","colab_type":"text"},"cell_type":"markdown","source":["# Imports\n"]},{"metadata":{"id":"rXnvv7SiE_g1","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{}],"base_uri":"https://localhost:8080/","height":88},"outputId":"ee18b3cb-d134-465d-fff7-f48e5b97b7c9","executionInfo":{"status":"ok","timestamp":1521579756308,"user_tz":240,"elapsed":7672,"user":{"displayName":"Patrick DeKelly","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"113168316542890578910"}}},"cell_type":"code","source":["# from datetime import datetime \n","# start_real = datetime.now()\n","import numpy as np\n","import pandas as pd\n","\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.cross_validation import train_test_split\n","from sklearn.pipeline import FeatureUnion\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","from keras.callbacks import Callback\n","\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.layers import Input, Dropout, Dense, concatenate, Embedding, Flatten, Activation, SpatialDropout1D\n","from keras.layers import Bidirectional, GRU, GlobalAveragePooling1D, GlobalMaxPooling1D\n","from keras.optimizers import Adam\n","from keras.models import Model\n","\n","from keras.preprocessing import sequence\n","from keras.models import Sequential\n","from keras.layers import LSTM\n","from keras.layers import MaxPooling1D, Conv1D\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","from nltk.tokenize import sent_tokenize, word_tokenize\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","import os\n","os.environ['OMP_NUM_THREADS'] = '4'\n","\n","import re\n","import math\n","# set seed\n","np.random.seed(123)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n","  \"This module will be removed in 0.20.\", DeprecationWarning)\n","Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"rZVK73poaqEg","colab_type":"text"},"cell_type":"markdown","source":["This block is to set up and/or alter GPU settings. Remove if not using GPU"]},{"metadata":{"id":"9njJV7ffF8HV","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# GPU acceleration\n","import os\n","os.environ[\"THEANO_FLAGS\"] = \"mode=FAST_RUN,device=gpu,floatX=float32\"\n","# import theano\n","# don't overload gpu\n","from keras import backend as K\n","config = K.tf.ConfigProto()\n","config.gpu_options.allow_growth = True\n","session = K.tf.Session(config=config)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"R5K8PW8fE_hL","colab_type":"text"},"cell_type":"markdown","source":["# Read in data\n","change this to target where you keep your train and test data. I also use the sample_submission later on for formating the final submission so grab that too."]},{"metadata":{"id":"RcMRi-w2E_hN","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["train = pd.read_csv('drive/Toxic_Comment/train.csv')\n","test = pd.read_csv('drive/Toxic_Comment/test.csv')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"XFUwGfuDE_hS","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{},{}],"base_uri":"https://localhost:8080/","height":393},"outputId":"51b22eea-7cbd-42af-eb94-45f790911ead","executionInfo":{"status":"ok","timestamp":1521579779971,"user_tz":240,"elapsed":328,"user":{"displayName":"Patrick DeKelly","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"113168316542890578910"}}},"cell_type":"code","source":["print(train.shape[0])\n","print(test.shape[0])\n","train[:10]"],"execution_count":0,"outputs":[{"output_type":"stream","text":["159571\n","153164\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>comment_text</th>\n","      <th>toxic</th>\n","      <th>severe_toxic</th>\n","      <th>obscene</th>\n","      <th>threat</th>\n","      <th>insult</th>\n","      <th>identity_hate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0000997932d777bf</td>\n","      <td>Explanation\\nWhy the edits made under my usern...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>000103f0d9cfb60f</td>\n","      <td>D'aww! He matches this background colour I'm s...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>000113f07ec002fd</td>\n","      <td>Hey man, I'm really not trying to edit war. It...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0001b41b1c6bb37e</td>\n","      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0001d958c54c6e35</td>\n","      <td>You, sir, are my hero. Any chance you remember...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>00025465d4725e87</td>\n","      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0002bcb3da6cb337</td>\n","      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>00031b1e95af7921</td>\n","      <td>Your vandalism to the Matt Shirvington article...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>00037261f536c51d</td>\n","      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>00040093b2687caa</td>\n","      <td>alignment on this subject and which are contra...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                 id                                       comment_text  toxic  \\\n","0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n","1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n","2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n","3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n","4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n","5  00025465d4725e87  \"\\n\\nCongratulations from me as well, use the ...      0   \n","6  0002bcb3da6cb337       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1   \n","7  00031b1e95af7921  Your vandalism to the Matt Shirvington article...      0   \n","8  00037261f536c51d  Sorry if the word 'nonsense' was offensive to ...      0   \n","9  00040093b2687caa  alignment on this subject and which are contra...      0   \n","\n","   severe_toxic  obscene  threat  insult  identity_hate  \n","0             0        0       0       0              0  \n","1             0        0       0       0              0  \n","2             0        0       0       0              0  \n","3             0        0       0       0              0  \n","4             0        0       0       0              0  \n","5             0        0       0       0              0  \n","6             1        1       0       1              0  \n","7             0        0       0       0              0  \n","8             0        0       0       0              0  \n","9             0        0       0       0              0  "]},"metadata":{"tags":[]},"execution_count":5}]},{"metadata":{"id":"wbt3NANM8NDZ","colab_type":"text"},"cell_type":"markdown","source":["Split the training set into a train and validation set."]},{"metadata":{"id":"aHZS8qkGE_h5","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{}],"base_uri":"https://localhost:8080/","height":68},"outputId":"c27e0dd0-0ff8-44a7-d5c4-aeb959d3d7e9","executionInfo":{"status":"ok","timestamp":1521579781298,"user_tz":240,"elapsed":393,"user":{"displayName":"Patrick DeKelly","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"113168316542890578910"}}},"cell_type":"code","source":["train, valid = train_test_split(train, random_state=233, train_size=0.95)\n","\n","n_train = train.shape[0]\n","n_test = test.shape[0]\n","n_valid = valid.shape[0]\n","\n","print(\"Training on\", n_train, \"examples\")\n","print(\"Validating on\", n_valid, \"examples\")\n","print(\"Testing on\", n_test, \"examples\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Training on 151592 examples\n","Validating on 7979 examples\n","Testing on 153164 examples\n"],"name":"stdout"}]},{"metadata":{"id":"kfvBcHW6bigt","colab_type":"text"},"cell_type":"markdown","source":["Note: There are no NA values in this data, otherwise we would remove them here."]},{"metadata":{"id":"hMtzIjePE_iN","colab_type":"text"},"cell_type":"markdown","source":["# Preprocessing the data\n","I've tried several string preprocessing steps but all of them actually have resulted in no improvement or a ***worse*** fit than just leaving the comment_text otherwise raw before tokenizing. Some classic preprocessing steps might end up helping a little, but pretty much all preprocessing concerns are handled by the tokenizer, vectors, or just the RNN model in general.\n","\n","-Removing stopwords or stemming words just gives the RNN less to work with. If there is enough data, an RNN can extract extra meaning from having tenses and such.\n","\n","-Low corrilation words,typos,ect are removed with the Max_words in the tokenizer\n","\n","-Punctuation is also removed during tokenization. Keeping some did not help the model."]},{"metadata":{"id":"LLcuN0-IdAUR","colab_type":"text"},"cell_type":"markdown","source":["# Time to Tokenize\n","This turns the text into numerical tokens. Also note that this step also removes all punctuation, rare words, and non words from the data on it's own. Max_words is how many different words/tokens we want to have in our texts. In this case, only the 100000 most common will be concidered. This is an easy variable that can be changed up and down for a change in fit. Tweet Tokenizer also work well on this set."]},{"metadata":{"id":"ZCQG4G7PE_iW","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{}],"base_uri":"https://localhost:8080/","height":102},"outputId":"c21527e9-8304-494a-d0ff-23b1e1c9ae78","executionInfo":{"status":"ok","timestamp":1521400084835,"user_tz":240,"elapsed":37893,"user":{"displayName":"Patrick DeKelly","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"113168316542890578910"}}},"cell_type":"code","source":["%%time\n","\n","Max_words = 100000\n","print(\"Transforming text data to sequences...\")\n","raw_text = np.hstack([full_df.comment.str.lower()])\n","\n","print(\"   Fitting tokenizer...\")\n","tok_raw = Tokenizer(num_words = Max_words,\n","                   #charaters in this filter string are removed before tokenizing \n","                    filters='.!,?\"#$%&()*+-/:;<=>@[\\\\]^_`{|}~\\t\\n')\n","tok_raw.fit_on_texts(raw_text)\n","\n","train = train['comment_text'].values\n","valid = valid['comment_text'].values\n","test = test['comment_text'].value\n","\n","print(\"   Transforming text to sequences...\")\n","train_tokens = tok_raw.texts_to_sequences(train)\n","valid_tokens = tok_raw.texts_to_sequences(valid)\n","test_tokens = tok_raw.texts_to_sequences(test)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Transforming text data to sequences...\n","   Fitting tokenizer...\n","   Transforming text to sequences...\n","CPU times: user 37.5 s, sys: 419 ms, total: 37.9 s\n","Wall time: 37.3 s\n"],"name":"stdout"}]},{"metadata":{"id":"pb4_BSeGeXiT","colab_type":"text"},"cell_type":"markdown","source":["This sets the lengths of all the token arrays to Max_length. Token arrays that have less \"words\" than Max_length get padded with 0s and token arrays with more \"words\" get cut short. Max_length is another easy variable to change to adjust fit."]},{"metadata":{"id":"8ClVnXJ0E_im","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["Max_length = 150\n","\n","X_train = sequence.pad_sequences(train_tokens, maxlen=Max_length)\n","X_test = sequence.pad_sequences(test_tokens, maxlen=Max_length)\n","X_valid = sequence.pad_sequences(valid_tokens, maxlen=Max_length)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"1ncF6ldPeov-","colab_type":"text"},"cell_type":"markdown","source":["Set the Y variables."]},{"metadata":{"id":"zziugBbCE_jO","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["Y_var = ['toxic','severe_toxic','obscene', 'threat','insult','identity_hate']\n","\n","Y_train = train[Y_var].values\n","\n","\n","Y_valid = valid[Y_var].values"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5tIS_UKKpSlW","colab_type":"text"},"cell_type":"markdown","source":["# Put a GLoVe on it!\n","This puts the glove word vectors into the dataset. The text file is big and, depending on your space, it may overload memory. It is fine in Collaboratory, with it's 12gb memory limit. However, there will likely be a memory warning that you can ignore after these blocks finish. (Takes ~3 minutes) Download the glove vectors here and path the EMBEDDING_FILE to them (other glove vectors work here too) https://www.kaggle.com/sebastianmarkow/glove.42b.300d/data "]},{"metadata":{"id":"G57J-UARphJN","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["EMBEDDING_FILE = 'drive/Toxic_Comment/glove.840B.300d.txt'"],"execution_count":0,"outputs":[]},{"metadata":{"id":"WD1sFIVnk-Zw","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{}],"base_uri":"https://localhost:8080/","height":51},"outputId":"dee4e303-70d9-4867-e58f-245b93662029","executionInfo":{"status":"ok","timestamp":1521400358058,"user_tz":240,"elapsed":265220,"user":{"displayName":"Patrick DeKelly","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"113168316542890578910"}}},"cell_type":"code","source":["%%time\n","embeddings_index = {}\n","with open(EMBEDDING_FILE,encoding='utf8') as f:\n","    for line in f:\n","        values = line.rstrip().rsplit(' ')\n","        word = values[0]\n","        coefs = np.asarray(values[1:], dtype='float32')\n","        embeddings_index[word] = coefs"],"execution_count":0,"outputs":[{"output_type":"stream","text":["CPU times: user 3min 40s, sys: 6.54 s, total: 3min 47s\n","Wall time: 4min 24s\n"],"name":"stdout"}]},{"metadata":{"id":"jsM1gYiLp77U","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{}],"base_uri":"https://localhost:8080/","height":51},"outputId":"e8f3d2a4-514e-49bb-e0ef-c4edfc784c1c","executionInfo":{"status":"ok","timestamp":1521400360111,"user_tz":240,"elapsed":759,"user":{"displayName":"Patrick DeKelly","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"113168316542890578910"}}},"cell_type":"code","source":["%%time\n","Embed_size = 300\n","word_index = tok_raw.word_index\n","#prepare embedding matrix\n","num_words = min(Max_words, len(word_index) + 1)\n","embedding_matrix = np.zeros((num_words, Embed_size))\n","for word, i in word_index.items():\n","    if i >= Max_words:\n","        continue\n","    embedding_vector = embeddings_index.get(word)\n","    if embedding_vector is not None:\n","        # words not found in embedding index will be all-zeros.\n","        embedding_matrix[i] = embedding_vector"],"execution_count":0,"outputs":[{"output_type":"stream","text":["CPU times: user 330 ms, sys: 29 ms, total: 359 ms\n","Wall time: 356 ms\n"],"name":"stdout"}]},{"metadata":{"id":"QZHmuVo9E_jd","colab_type":"text"},"cell_type":"markdown","source":["# Make the RNN model\n","Here is the model. It is one heavy bidirectional GRU layer. Bidirectional RNNs run twice, once forward and once backwards, to effectively allow the model to look forward and backwards on the sequence to determine the output. This is followed by a 1D CNN to help look for patterns, then pooled using both Average and Max Pooling.\n"]},{"metadata":{"id":"NYS33YAnE_ka","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{}],"base_uri":"https://localhost:8080/","height":459},"outputId":"77ff907d-0163-4466-fbd1-782f63688036","executionInfo":{"status":"ok","timestamp":1521400829125,"user_tz":240,"elapsed":1793,"user":{"displayName":"Patrick DeKelly","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"113168316542890578910"}}},"cell_type":"code","source":["def get_model():\n","    model = Sequential()\n","    inp = Input(shape=(Max_length, ))\n","    x = Embedding(Max_words, Embed_size, weights=[embedding_matrix], trainable=False)(inp)\n","    x = SpatialDropout1D(0.2)(x)\n","    x = Bidirectional(GRU(128, return_sequences=True,dropout=0.1,recurrent_dropout=0.1))(x)\n","    x = Conv1D(64, kernel_size = 3, padding = \"valid\", kernel_initializer = \"glorot_uniform\")(x)\n","    avg_pool = GlobalAveragePooling1D()(x)\n","    max_pool = GlobalMaxPooling1D()(x)\n","    x = concatenate([avg_pool, max_pool])\n","    outp = Dense(6, activation=\"sigmoid\")(x)\n","    \n","    model = Model(inputs=inp, outputs=outp)\n","    model.compile(loss='binary_crossentropy',\n","                  optimizer=Adam(lr=0.001),\n","                  metrics=['accuracy'],\n","                 )\n","\n","    return model\n","\n","model = get_model()\n","\n","model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_8 (InputLayer)            (None, 150)          0                                            \n","__________________________________________________________________________________________________\n","embedding_8 (Embedding)         (None, 150, 300)     30000000    input_8[0][0]                    \n","__________________________________________________________________________________________________\n","spatial_dropout1d_8 (SpatialDro (None, 150, 300)     0           embedding_8[0][0]                \n","__________________________________________________________________________________________________\n","bidirectional_8 (Bidirectional) (None, 150, 256)     329472      spatial_dropout1d_8[0][0]        \n","__________________________________________________________________________________________________\n","conv1d_8 (Conv1D)               (None, 148, 64)      49216       bidirectional_8[0][0]            \n","__________________________________________________________________________________________________\n","global_average_pooling1d_8 (Glo (None, 64)           0           conv1d_8[0][0]                   \n","__________________________________________________________________________________________________\n","global_max_pooling1d_8 (GlobalM (None, 64)           0           conv1d_8[0][0]                   \n","__________________________________________________________________________________________________\n","concatenate_8 (Concatenate)     (None, 128)          0           global_average_pooling1d_8[0][0] \n","                                                                 global_max_pooling1d_8[0][0]     \n","__________________________________________________________________________________________________\n","dense_8 (Dense)                 (None, 6)            774         concatenate_8[0][0]              \n","==================================================================================================\n","Total params: 30,379,462\n","Trainable params: 379,462\n","Non-trainable params: 30,000,000\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"66MwE37cf5Bj","colab_type":"text"},"cell_type":"markdown","source":["# Callbacks \n","Adds 2 callbacks to the model, checkpoint and early stopping. Checkpoint saves the weights at every epoch that improves the loss while early stopping stops the model if loss declines. I like early stopping callback methods but it is not ideal for this competition. The model should be trained right now in about 2 epochs and will clearly start overfitting after that. Maybe with a heavier model. Still, it can help."]},{"metadata":{"id":"aQrxnh0UE_ki","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["file_path=\"weights_base.best.hdf5\"\n","checkpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n","early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=1)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"QhTPiK42Lcps","colab_type":"text"},"cell_type":"markdown","source":["Load any model weights here. "]},{"metadata":{"id":"hS-GcYSlR6cb","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# model.load_weights('drive/Toxic_Comment/1_epoch_base_weights.h5')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JNW89pHihAvo","colab_type":"text"},"cell_type":"markdown","source":["# Trian the Model\n","This block trains the model. Each epoch takes about 20 minutes at this setting (on Colabs anyways). Raising the batch_size will speed it up a lot, but probably lose some accuracy and maybe need more epochs. 2, maybe 3, epochs should be ideal. "]},{"metadata":{"id":"HrN8jG3hE_ks","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{},{},{},{},{},{},{},{}],"base_uri":"https://localhost:8080/","height":1815},"outputId":"df42c3bf-75b1-4b61-cda2-72f8822b198c","executionInfo":{"status":"error","timestamp":1521405868380,"user_tz":240,"elapsed":3309027,"user":{"displayName":"Patrick DeKelly","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"113168316542890578910"}}},"cell_type":"code","source":["%%time\n","\n","from numpy.random import seed\n","seed(123)\n","from tensorflow import set_random_seed\n","set_random_seed(123)\n","\n","model_callbacks = [checkpoint, early]\n","model.fit(X_train, Y_train,\n","          batch_size=64,\n","          epochs=3,\n","          verbose=1,\n","          validation_data=(X_valid, Y_valid),\n","          callbacks = model_callbacks)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 151592 samples, validate on 7979 samples\n","Epoch 1/4\n"," 43200/151592 [=======>......................] - ETA: 12:27 - loss: 0.0447 - acc: 0.9829"],"name":"stdout"},{"output_type":"stream","text":["151552/151592 [============================>.] - ETA: 0s - loss: 0.0431 - acc: 0.9834"],"name":"stdout"},{"output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r151592/151592 [==============================] - 1063s 7ms/step - loss: 0.0431 - acc: 0.9834 - val_loss: 0.0430 - val_acc: 0.9835\n","\n","Epoch 00001: val_loss improved from 0.04440 to 0.04299, saving model to weights_base.best.hdf5\n","Epoch 2/4\n"," 15424/151592 [==>...........................] - ETA: 15:43 - loss: 0.0404 - acc: 0.9849"],"name":"stdout"},{"output_type":"stream","text":["151552/151592 [============================>.] - ETA: 0s - loss: 0.0404 - acc: 0.9844"],"name":"stdout"},{"output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r151592/151592 [==============================] - 1070s 7ms/step - loss: 0.0404 - acc: 0.9844 - val_loss: 0.0429 - val_acc: 0.9830\n","\n","Epoch 00002: val_loss improved from 0.04299 to 0.04287, saving model to weights_base.best.hdf5\n","Epoch 3/4\n"," 15424/151592 [==>...........................] - ETA: 15:44 - loss: 0.0370 - acc: 0.9854"],"name":"stdout"},{"output_type":"stream","text":["151552/151592 [============================>.] - ETA: 0s - loss: 0.0381 - acc: 0.9851"],"name":"stdout"},{"output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r151592/151592 [==============================] - 1054s 7ms/step - loss: 0.0381 - acc: 0.9851 - val_loss: 0.0444 - val_acc: 0.9822\n","\n","Epoch 00003: val_loss did not improve\n","Epoch 4/4\n"," 17408/151592 [==>...........................] - ETA: 15:13 - loss: 0.0340 - acc: 0.9867"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-59-c29a35b7b6e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\nfrom numpy.random import seed\\nseed(123)\\nfrom tensorflow import set_random_seed\\nset_random_seed(123)\\n\\nmodel_callbacks = [checkpoint, early]\\nmodel.fit(X_train, Y_train,\\n          batch_size=64,\\n          epochs=4,\\n          verbose=1,\\n          validation_data=(X_dev, Y_dev),\\n          callbacks = model_callbacks)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1359\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[0;32m-> 1340\u001b[0;31m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"id":"M495lZOEhuN-","colab_type":"text"},"cell_type":"markdown","source":["# Prediction\n","This makes the prediction on the test data. The model saves the best weights to file_path so uncomment that line to load them if your model stopped on a bad epoch."]},{"metadata":{"id":"J_4wI-ZrE_lN","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{}],"base_uri":"https://localhost:8080/","height":51},"outputId":"51365188-7c81-43c3-b1fc-f5fb01b607a6","executionInfo":{"status":"ok","timestamp":1521405963125,"user_tz":240,"elapsed":86054,"user":{"displayName":"Patrick DeKelly","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"113168316542890578910"}}},"cell_type":"code","source":["%%time\n","# model.load_weights(file_path)\n","Y_test = model.predict(X_test, batch_size=256)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["CPU times: user 1min 16s, sys: 10.9 s, total: 1min 27s\n","Wall time: 1min 25s\n"],"name":"stdout"}]},{"metadata":{"id":"J7Dt9JgNP6RD","colab_type":"text"},"cell_type":"markdown","source":["# Make the submission\n","My best single model submission was 0.9835 ROC with this notebook. That is pretty much the highest a model can get without ensembling. Based on code that was posted after the competition, the highest single model model prediction was only around ~0.9840 ROC. So this notebook was pretty close to optimal in the Toxic Comments Compo."]},{"metadata":{"id":"x162EEIAJGBG","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["submission = pd.read_csv(\"drive/Toxic_Comment/sample_submission.csv\")\n","submission[Y_var] = Y_test\n","submission.to_csv(\"drive/Toxic_Comment/Glove_RNN_Submission10.csv\", index=False)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"lWLAFV84iiOs","colab_type":"text"},"cell_type":"markdown","source":["This block permenently saves the weights. This can be read in with read_text and/or just loaded into a model with model.load_weights(the file path) then can skip training or continue to train from there."]},{"metadata":{"id":"f4GLNauvNlIk","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["\n","model.save_weights('drive/Toxic_Comment/my_model_weights.h5')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ENgesJlXl6Im","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}