{
  "cells": [
    {
      "metadata": {
        "_uuid": "1475ac4b3ae9d88771d6b38f32962909d76a4697"
      },
      "cell_type": "markdown",
      "source": "# Creating a New Word \"Game\"\nWe have all heard of anagrams, where you take a word or phrase and shuffle the letters to make a new one. However, I was wondering what if, instead of letters, what if we shuffled the words base sounds around. The ARPAbet is a set of phonetic transcription codes developed by Advanced Research Projects Agency (ARPA) in the 1970s. It allows us to break down words farther into visual representation of speech sounds. Now what if we shuffled these around to make, what I am calling, an ARPAbet-agram. This is a bit more complex than anyone would ever care to deal with (It makes anagrams look pretty easy by comparasion). Calling it a word \"game\" is somewhat generous, but we can make a computer do all that teadious work to find ARPAbetagrams and we can just enjoy the results. Feel free to play with this notebook or just download the outputed .CSV file of ~135,000 words and their possible ARPAbetagrams. \n\n## Defining a ARPAbetagram\n\nI will define an ARPAbetagram as a word (or phrase) whose formed by rearranging the ARPAbet phones of another. 2 additional rules:\n\n-The ARPAbetagram cannot be a homophone\n\n-Stresses can be ignored. Since I'm making this up, I can do that. It is like ignoring spaces or capitalization in anagrams. I find it makes for more interseting results. The ARPAbet-agrams are sparse enough without them.\n\nAs an example, the word 'accounts' has a pronuncation in ARPAbet as \"AH K AW N T S\" and the word 'countess' has a pronuncation in ARPAbet as \"K AW N T AH S\". Note that both words use the same phones (AH AW K N S T) so are concidered an ARPAbetagram of each other."
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nimport os\nprint(os.listdir(\"../input\"))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "collapsed": true,
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "dictionary = open('../input/cmudict.dict', 'r')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e1f75fc79126f3c3011805247a8e08b7070be3cd"
      },
      "cell_type": "markdown",
      "source": "# Process ARPAbet dictionary\nFirst we'll reformat the dictionary into a Dataset with the word and it's pronunciation. I am removing numbers from the set as numbers only indicate minor stress points for vowels in ARPAbet. Try as I might, I am unable to here the difference between these stresses so I am discounting them in this exercise."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "050d98150fde2f0252c129d499695cf973bc9682",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "%%time\n\nwith dictionary as f:\n    phonics = [line.rstrip('\\n') for line in f]\n\nword = []\npronunciation = []\npronunciation_sorted = []\n\nfor x in phonics:\n    x = x.split(' ')\n    word.append(x[0])\n    p = ' '.join(x[1:])\n    # removing numbers from pronunciation\n    p = p.replace('0','')\n    p = p.replace('1','')\n    p = p.replace('2','')\n    pronunciation.append(p)\n    a = p.split(' ')\n    a.sort()\n    a = ' '.join(a)\n    pronunciation_sorted.append(a)\n\ndf = pd.DataFrame({\n        \"word\": word,\n        \"pronunciation\": pronunciation,\n        \"pronunciation_sorted\": pronunciation_sorted\n    })\n\n# add placeholder columns\ndf['ARPAbetagrams'] = ''\ndf['index'] = df.index\ndf[:10]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f8bbaa8006835a78fa14b4a2e6c028c8d3f72792"
      },
      "cell_type": "markdown",
      "source": "# Find all ARPAbetagram\nNote: This runs a but slow but gets the job done. Takes ~1 hour to complete. The result will be a new column listing all the ARPAbetagrams of that word."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "781d7702f376d98e6fbc9b45619110965461c544",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "%%time\ndef fillARPAbetagrams(line):\n    word = line[0]\n    cp = line[1]\n    cpa = line[2]\n    p = 0\n    i = line[3]\n    if i % 1350 == 0:\n        print(str(i/1350)+'% done')\n    \n    pg = df.loc[(df['pronunciation_sorted'] == cpa) & (df['pronunciation'] != cp)]['word'].values.tolist()\n    \n    pg = ','.join(pg)\n    h = ''\n    return pg\ndf['ARPAbetagrams'] = df[['word', 'pronunciation', 'pronunciation_sorted', 'index']].apply(fillARPAbetagrams, axis = 1)\n\ndf.drop(['index'], axis=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5d3b584509abdd2f92f2b48ada1b4386ff5c8a92"
      },
      "cell_type": "markdown",
      "source": "# Look at the Results\nAs you can see, ARPAbetagrams are pretty rare. Most words have none. Many words only have a few because the dataset inculdes some questionable words. That being said, there are some pretty interesting and unexpected ARPAbetagrams mixed throughout. Making a program that can go through a phrase and find ARPAbetagrams of it might be phase 2 of this notebook, but I will leave it here for now.\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e26b5a445d1982f9c8d558607550d0235b0e4b68",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# df.loc[(df['word'] == 'accord')]\ndf[:50]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f8b31367db715c55ce5947d311702c1054f3040a"
      },
      "cell_type": "markdown",
      "source": "# Output the CSV File\nEnjoy going through the dataset"
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "be4efc652b1ea028146df7a60148832b36e41602"
      },
      "cell_type": "code",
      "source": "df.to_csv(\"ARPAbetagrams_Dataset.csv\", index=False, header=True)",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}